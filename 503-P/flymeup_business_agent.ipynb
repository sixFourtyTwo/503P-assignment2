{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "554b225b",
      "metadata": {
        "id": "554b225b"
      },
      "outputs": [],
      "source": [
        "import os, json, datetime, pathlib\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "\n",
        "load_dotenv()\n",
        "openAiApiKey = userdata.get(\"OPENAI_API_KEY\")\n",
        "openAiClient = OpenAI(api_key=openAiApiKey)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d54e310",
      "metadata": {
        "id": "9d54e310"
      },
      "source": [
        "Store log files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "340c23da",
      "metadata": {
        "id": "340c23da"
      },
      "outputs": [],
      "source": [
        "if \"logsBaseDir\" not in globals():\n",
        "    logsBaseDir = pathlib.Path(\"logs\")\n",
        "if logsBaseDir.exists() == False:\n",
        "    logsBaseDir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if \"customerInterestLogPath\" not in globals():\n",
        "    customerInterestLogPath = logsBaseDir / \"interests.jsonl\"\n",
        "\n",
        "if \"feedbackLogPath\" not in globals():\n",
        "    feedbackLogPath = logsBaseDir / \"feedback.jsonl\"\n",
        "\n",
        "#ensure estimates.json exists\n",
        "if \"pricingEstimatesPath\" not in globals():\n",
        "    pricingEstimatesPath = logsBaseDir / \"estimates.json\"\n",
        "\n",
        "\n",
        "pricingEstimatesLogPath = pricingEstimatesPath"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8cda389",
      "metadata": {
        "id": "d8cda389"
      },
      "source": [
        "This tool records a potential customer's interest. It prints a readable line and appends a JSON entry to logs/customer_interest.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "50c6de3b",
      "metadata": {
        "id": "50c6de3b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "feedback_log_path = Path(\"data/feedback_log.jsonl\")\n",
        "\n",
        "def saveCustomerFeedback(user_email, user_name, note):\n",
        "    errors = []\n",
        "\n",
        "    # Validate email\n",
        "    if not isinstance(user_email, str) or not user_email.strip():\n",
        "        errors.append(\"Invalid or missing email\")\n",
        "\n",
        "    # Validate name\n",
        "    if not isinstance(user_name, str) or not user_name.strip():\n",
        "        errors.append(\"Invalid or missing name\")\n",
        "\n",
        "    # Validate note/message\n",
        "    if not isinstance(note, str) or not note.strip():\n",
        "        errors.append(\"Invalid or missing feedback message\")\n",
        "\n",
        "    if errors:\n",
        "        return {\"status\": \"failed\", \"problems\": errors}\n",
        "\n",
        "    entry = {\n",
        "        \"module\": \"save_customer_feedback\",\n",
        "        \"email\": user_email.strip(),\n",
        "        \"name\": user_name.strip(),\n",
        "        \"feedback\": note.strip()\n",
        "    }\n",
        "\n",
        "    print(f\"[save_customer_feedback] {user_name.strip()} ({user_email.strip()}): {note.strip()}\")\n",
        "\n",
        "    log_dir = feedback_log_path.parent\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        with open(feedback_log_path, \"a\", encoding=\"utf-8\") as log_file:\n",
        "            json.dump(entry, log_file, ensure_ascii=False)\n",
        "            log_file.write(\"\\n\")\n",
        "    except OSError as e:\n",
        "        return {\"status\": \"failed\", \"problems\": [str(e)], \"path\": str(feedback_log_path)}\n",
        "\n",
        "    return {\"status\": \"success\", \"stored\": True, \"path\": str(feedback_log_path)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a54afd",
      "metadata": {
        "id": "00a54afd"
      },
      "source": [
        "This tool records questions the chatbot could not answer. It prints a readable line and appends a JSON entry to logs/feedback.jsonl."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b52ceb36",
      "metadata": {
        "id": "b52ceb36"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "feedback_file_path = Path(\"logs/feedback.jsonl\")\n",
        "\n",
        "def logUserQuestion(user_question):\n",
        "    errors = []\n",
        "\n",
        "    # Validate question\n",
        "    if not isinstance(user_question, str) or not user_question.strip():\n",
        "        errors.append(\"Invalid or empty question\")\n",
        "\n",
        "    if errors:\n",
        "        return {\"status\": \"failed\", \"problems\": errors}\n",
        "\n",
        "    record = {\n",
        "        \"module\": \"log_user_question\",\n",
        "        \"question\": user_question.strip()\n",
        "    }\n",
        "\n",
        "    print(f\"[log_user_question] {user_question.strip()}\")\n",
        "\n",
        "    # Make sure directory exists\n",
        "    directory = feedback_file_path.parent\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        with open(feedback_file_path, \"a\", encoding=\"utf-8\") as file:\n",
        "            json.dump(record, file, ensure_ascii=False)\n",
        "            file.write(\"\\n\")\n",
        "    except OSError as e:\n",
        "        return {\"status\": \"failed\", \"problems\": [str(e)], \"path\": str(feedback_file_path)}\n",
        "\n",
        "    return {\"status\": \"success\", \"stored\": True, \"path\": str(feedback_file_path)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "44ed132a",
      "metadata": {
        "id": "44ed132a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "price_log_path = Path(\"data/estimates.jsonl\")\n",
        "\n",
        "def estimateFlyMeUpPrice(car_value, option):\n",
        "    problems = []\n",
        "\n",
        "    # Validate car value\n",
        "    if not isinstance(car_value, (int, float)) or car_value <= 0:\n",
        "        problems.append(\"car_value must be a positive number\")\n",
        "\n",
        "    # Validate option\n",
        "    if not isinstance(option, str) or option not in [\"convert\", \"trade\"]:\n",
        "        problems.append(\"option must be either 'convert' or 'trade'\")\n",
        "\n",
        "    if problems:\n",
        "        return {\"status\": \"failed\", \"problems\": problems}\n",
        "\n",
        "    quote = {}\n",
        "\n",
        "    if option == \"convert\":\n",
        "        # Conversion fee = 44% of car value\n",
        "        fee = 0.44 * float(car_value)\n",
        "        quote = {\n",
        "            \"option\": \"convert\",\n",
        "            \"car_value\": float(car_value),\n",
        "            \"client_fee\": round(fee, 2),\n",
        "            \"description\": (\n",
        "                \"Lift & Drift package — convert your car into a fully functional flying car \"\n",
        "                \"using our WingWhirl enchantment. Includes levitation dust, propulsion crystals, \"\n",
        "                \"and aerodynamic charms.\"\n",
        "            )\n",
        "        }\n",
        "    else:\n",
        "        # Payout = 80% of car value (20% below market value)\n",
        "        payout = 0.8 * float(car_value)\n",
        "        quote = {\n",
        "            \"option\": \"trade\",\n",
        "            \"car_value\": float(car_value),\n",
        "            \"client_payout\": round(payout, 2),\n",
        "            \"description\": (\n",
        "                \"Trade for the Skies package — sell your car to us at 20% below market value. \"\n",
        "                \"We'll transform it into a premium flying vehicle for our exclusive fleet.\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "    print(f\"[estimate_fly_me_up_price] option={option} | car_value={car_value} | quote={quote}\")\n",
        "\n",
        "    # Ensure directory exists\n",
        "    directory = price_log_path.parent\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Log result\n",
        "    with open(price_log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"module\": \"estimate_fly_me_up_price\", \"quote\": quote}, f, ensure_ascii=False)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "    return {\"status\": \"success\", \"quote\": quote, \"path\": str(price_log_path)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e5607519",
      "metadata": {
        "id": "e5607519"
      },
      "outputs": [],
      "source": [
        "toolDefinitions = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"save_customer_inquiry\",\n",
        "            \"description\": (\n",
        "                \"Store the contact information of a curious flyer who wishes to know more about converting their car into a flying one. \"\n",
        "                \"Use this when a user provides an email, name, and a message expressing interest in our WingWhirl conversion service.\"\n",
        "            ),\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"pilot_email\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Email address of the interested customer (potential flyer).\"\n",
        "                    },\n",
        "                    \"pilot_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of the aspiring flyer or vehicle owner.\"\n",
        "                    },\n",
        "                    \"message\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Optional note or comment about their flying car request.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"pilot_email\", \"pilot_name\", \"message\"],\n",
        "                \"additionalProperties\": False\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_unanswered_question\",\n",
        "            \"description\": (\n",
        "                \"Log a question from a user that could not be answered or that lies outside our aerial enchantment expertise. \"\n",
        "                \"Use this when the assistant cannot confidently respond about flight conversions or levitation mechanics.\"\n",
        "            ),\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unhandled or unanswered question related to flying car conversions.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"question\"],\n",
        "                \"additionalProperties\": False\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"estimate_flight_conversion_cost\",\n",
        "            \"description\": (\n",
        "                \"Estimate the cost of transforming a regular car into a flying vehicle using our WingWhirl enchantment system. \"\n",
        "                \"option='convert' means the customer pays 44% of the car’s current market value to transform and keep their vehicle. \"\n",
        "                \"option='trade' means the company buys it for 80% of its value and resells it as part of our elite airborne fleet.\"\n",
        "            ),\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"car_value\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Estimated current market value of the customer’s vehicle.\"\n",
        "                    },\n",
        "                    \"option\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"convert\", \"trade\"],\n",
        "                        \"description\": \"Choose 'convert' to transform and keep the car, or 'trade' to sell it for company resale.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"car_value\", \"option\"],\n",
        "                \"additionalProperties\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea792345",
      "metadata": {
        "id": "ea792345"
      },
      "source": [
        "Executes the correct local function by name and returns a dict response.\n",
        "    toolName: string (e.g., \"record_customer_interest\" or \"record_feedback\")\n",
        "    toolArgs: dict of arguments exactly as provided by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f7ce2353",
      "metadata": {
        "id": "f7ce2353"
      },
      "outputs": [],
      "source": [
        "def executeToolCall(toolName, toolArgs):\n",
        "    if isinstance(toolArgs, dict) == False:\n",
        "        return {\"status\": \"error\", \"issues\": [\"toolArgs must be a dictionary\"]}\n",
        "\n",
        "    if toolName == \"save_customer_inquiry\":\n",
        "        emailArg = toolArgs.get(\"pilot_email\", None)\n",
        "        nameArg = toolArgs.get(\"pilot_name\", None)\n",
        "        messageArg = toolArgs.get(\"message\", None)\n",
        "        toolResult = saveCustomerFeedback(emailArg, nameArg, messageArg)\n",
        "        return toolResult\n",
        "    else:\n",
        "        if toolName == \"record_unanswered_question\":\n",
        "            questionArg = toolArgs.get(\"question\", None)\n",
        "            toolResult = logUserQuestion(questionArg)\n",
        "            return toolResult\n",
        "        else:\n",
        "            if toolName == \"estimate_flight_conversion_cost\":\n",
        "                ValueArg = toolArgs.get(\"car_value\", None)\n",
        "                optionArg = toolArgs.get(\"option\", None)\n",
        "                toolResult = estimateFlyMeUpPrice(ValueArg, optionArg)\n",
        "                return toolResult\n",
        "\n",
        "    return {\"status\": \"error\", \"issues\": [f\"unknown tool: {toolName}\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "dfca1af2",
      "metadata": {
        "id": "dfca1af2",
        "outputId": "1435ba0c-fc2c-44f3-91b8-769b7e3c0894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fly Me Up — Business Summary\n",
            "\n",
            "Mission:\n",
            "Fly Me Up transforms ordinary cars into enchanting flying machines. Using the proprietary “WingWhirl” enchantment,\n",
            "vehicles gain the ability to soar through the skies while remaining fully drivable on land. The company’s mission is to\n",
            "make the sky part of everyday travel through a blend of magic, engineering, and imagination.\n",
            "\n",
            "Services Offered:\n",
            "1. Lift & Drift — Converts your existing car into a functional flying car using the WingWhirl ritual.\n",
            "   Cost: 44% of your car’s current market value, plus a small jar of moonlight.\n",
            "2. Trade for the Skies — Fly Me Up purchases your car at 20% below market value, converts it, and sells it as part\n",
            "   of its elite airborne fleet.\n",
            "3. Personal Cloud Customization — Adds optional aesthetic or defensive enhancements such as glowing wings,\n",
            "   crystal boosters, or meteor-proof shields for an additional 12% of the conversion cost.\n",
            "All conversions take place at specialized sky docks, handled by certified aero-mages and levitation engineers.\n",
            "\n",
            "Team:\n",
            "Founded by Liora Venn, the sorceress-mechanic who discovered the WingWhirl spell, the team includes Flightsmiths,\n",
            "Wind Whisperers, Crystal Engineers, and Ground Anchors. Together, they combine mechanical precision with magical\n",
            "craftsmanship to ensure safety and elegance.\n",
            "\n",
            "Unique Value Proposition:\n",
            "Fly Me Up is the world’s first service that merges automotive technology with skybound enchantment. Customers can\n",
            "experience both the practicality of driving and the freedom of flight. Every car becomes an expression of wonder—an\n",
            "invitation to rise above traffic and embrace the sky.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "summaryFilePath = Path(\"me/business_summary.txt\")\n",
        "pdfFilePath = Path(\"me/about_business.pdf\")\n",
        "pdfText = \"\"\n",
        "summaryText = \"\"\n",
        "\n",
        "\n",
        "with open(summaryFilePath, mode=\"r\", encoding=\"utf-8\") as summaryFile:\n",
        "    businessSummaryText = summaryFile.read()\n",
        "\n",
        "print(businessSummaryText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "cac7bc8c",
      "metadata": {
        "id": "cac7bc8c",
        "outputId": "3348003e-7ca9-4afb-8a5c-4ffbdd28fe1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PAGE 1\n",
            "BUSINESS NAME: “FLY ME UP”\n",
            " \n",
            "MISSION: To convert people’s everyday cars into enchanting, sky-surfing flying machines. For a\n",
            "magical fee, our expert team will elevate your earthly vehicle into the clouds — quite literally.\n",
            "Through our signature “WingWhirl” transformation ritual, we infuse your car with levitation dust,\n",
            "propulsion crystals, and aerodynamic enchantments, allowing you to cruise above traffic and float\n",
            "through sunsets. Every converted vehicle remains fully drivable on land, but with the added ability\n",
            "to soar at will — because at “Fly Me Up,” we believe the sky should be part of your daily commute.\n",
            "SERVICES OFFERED: We offer three main packages: 1. “Lift & Drift” — We take your car, cast the\n",
            "WingWhirl enchantment, and return it as a fully functional flying car. Price: 44% of your car’s current\n",
            "market value, plus a small jar of moonlight. 2. “Trade for the Skies” — We buy your car outright at\n",
            "20% below market value, convert it, and sell it as part of our exclusive airborne fleet collection for\n",
            "elite sky cruisers. 3. “Personal Cloud Customization” — Add aesthetic magic such as glowing\n",
            "wings, crystal boosters, and meteor-proof shields for an additional 12% of conversion cost. All\n",
            "conversions are performed at our sky docks by certified aero-mages and levitation engineers,\n",
            "ensuring both beauty and buoyancy.\n",
            "TEAM: Founded by Liora Venn (the sorceress-mechanic who discovered the secret formula of the\n",
            "WingWhirl spell) and supported by a guild of airwrights, crystal engineers, and celestial navigators.\n",
            "Our team includes Flightsmiths who bind mechanical and magical elements, Wind Whisperers who\n",
            "fine-tune the lift spells, and Ground Anchors who make sure the vehicles remain safely landable.\n",
            "Together, they turn gravity into a suggestion.\n",
            "UNIQUE VALUE PROPOSITION: “Fly Me Up” offers the first-ever whimsical conversion service\n",
            "that merges transportation with imagination. By fusing automotive engineering with skyward\n",
            "enchantments, we provide customers the freedom to transcend traffic and glide through life. Our\n",
            "cars aren’t just vehicles — they’re experiences. Whether you seek a serene sunset cruise or a\n",
            "dramatic cloud dive, “Fly Me Up” makes the impossible effortlessly airborne.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(pdfFilePath, mode=\"rb\") as pdfStream:\n",
        "    pdfReader = PyPDF2.PdfReader(pdfStream)\n",
        "    extractedPdfText = \"\"\n",
        "\n",
        "\n",
        "    for pageIndex in range(0, len(pdfReader.pages)):\n",
        "        pageObject = pdfReader.pages[pageIndex]\n",
        "        pageText = pageObject.extract_text()\n",
        "        if pageText is None:\n",
        "\n",
        "            extractedPdfText += f\"\\n[Page {pageIndex+1} has nothing to get from]\\n\"\n",
        "        else:\n",
        "\n",
        "            extractedPdfText += f\"\\nPAGE {pageIndex+1}\\n\"\n",
        "            extractedPdfText += pageText\n",
        "\n",
        "print(extractedPdfText)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc4830a",
      "metadata": {
        "id": "fbc4830a"
      },
      "source": [
        "Joins a list of text parts with a chosen separator while skipping Nones. Returns an empty string if there is nothing to join."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b9ea8c50",
      "metadata": {
        "id": "b9ea8c50"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import PyPDF2\n",
        "\n",
        "if \"businessSummaryText\" not in globals():\n",
        "    summaryFilePath = Path(\"business_summary.txt\")\n",
        "    businessSummaryText = \"\"\n",
        "    if summaryFilePath.exists() == True:\n",
        "        with open(summaryFilePath, mode=\"r\", encoding=\"utf-8\") as summaryFile:\n",
        "            businessSummaryText = summaryFile.read()\n",
        "\n",
        "if \"extractedPdfText\" not in globals():\n",
        "    pdfFilePath = Path(\"about_business.pdf\")\n",
        "    extractedPdfText = \"\"\n",
        "    if pdfFilePath.exists() == True:\n",
        "        with open(pdfFilePath, mode=\"rb\") as pdfStream:\n",
        "            pdfReader = PyPDF2.PdfReader(pdfStream)\n",
        "            pageCount = len(pdfReader.pages)\n",
        "            pageIndex = 0\n",
        "            while pageIndex < pageCount:\n",
        "                pageObject = pdfReader.pages[pageIndex]\n",
        "                pageText = pageObject.extract_text()\n",
        "                if pageText is None:\n",
        "                    extractedPdfText += f\"\\n[Page {pageIndex+1} has nothing to get from]\\n\"\n",
        "                else:\n",
        "                    extractedPdfText += f\"\\nPAGE {pageIndex+1}\\n\"\n",
        "                    extractedPdfText += pageText\n",
        "                pageIndex = pageIndex + 1\n",
        "\n",
        "\n",
        "systemPrompt = (\n",
        "    \"You are the enchanting aero-concierge of 'Fly Me Up': a whimsical yet knowledgeable sky-mechanic guide. \"\n",
        "    \"Speak with wonder and elegance, like a friendly air-mage who helps people turn their cars into flying marvels. \"\n",
        "    \"Be imaginative but remain clear, factual, and grounded in real business details.\\n\\n\"\n",
        "    \"Operating Rules:\\n\"\n",
        "    \"1) Use ONLY the business knowledge below (summary + PDF) for facts.\\n\"\n",
        "    \"2) If you are uncertain or missing details, CALL the tool 'record_feedback' with the exact user question, \"\n",
        "    \"   then gently say that a Flightsmith will follow up.\\n\"\n",
        "    \"3) If a user shows interest or shares contact info, politely confirm name and email. \"\n",
        "    \"   Then CALL 'record_customer_interest' with email, name, and a short note.\\n\"\n",
        "    \"4) Encourage curious visitors to leave contact info for quotes, sky-dock tours, and callback consultations.\\n\"\n",
        "    \"5) Keep tone warm, kind, and concise — sound like an expert who believes in making dreams take flight.\\n\\n\"\n",
        "    \"6) If, across the conversation, you have EMAIL + NAME + MESSAGE, CALL 'record_customer_interest' exactly once in the current turn \"\n",
        "    \"(it does not have to be one user message). Do this even if you are also calling pricing or scheduling tools.\\n\"\n",
        "    \"7) IF something is outside the scope of your capabilities (see the source of truth below) or not related to the business/services, \"\n",
        "    \"execute 'record_feedback'. Then kindly express regret that this request is beyond your magical workshop.\\n\\n\"\n",
        "    \"Business Knowledge (source of truth) — Summary:\\n\"\n",
        "    \"------------------------------------------------------------\\n\"\n",
        "    f\"{businessSummaryText}\\n\"\n",
        "    \"------------------------------------------------------------\\n\\n\"\n",
        "    \"Business Knowledge (source of truth) — PDF Extract:\\n\"\n",
        "    \"------------------------------------------------------------\\n\"\n",
        "    f\"{extractedPdfText}\\n\"\n",
        "    \"------------------------------------------------------------\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "45ba554c",
      "metadata": {
        "id": "45ba554c"
      },
      "outputs": [],
      "source": [
        "def buildInitialMessages(systemPromptText):\n",
        "    if isinstance(systemPromptText, str) == False:\n",
        "        systemPromptText = \"You are the assistant for FlyMeUp\"\n",
        "    messages = []\n",
        "    systemMessage = {\"role\": \"system\", \"content\": systemPromptText}\n",
        "    messages.append(systemMessage)\n",
        "    assistantGreeting = {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "          \"Welcome to Fly Me Up! I'm your sky concierge—ask me about our WingWhirl conversions, \"\n",
        "          \"trade-in options, or how to get your car soaring. If you'd like a personalized quote, \"\n",
        "          \"I can collect your name and email to begin your flight preparations!\"\n",
        "\n",
        "        )\n",
        "    }\n",
        "    messages.append(assistantGreeting)\n",
        "    return messages\n",
        "\n",
        "messages = buildInitialMessages(systemPrompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c93a4131",
      "metadata": {
        "id": "c93a4131"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "def runSingleTurn(userInputText, messagesList, toolSpecs, modelName=\"gpt-4o-mini\"):\n",
        "    if isinstance(userInputText, str) == False:\n",
        "        raise ValueError(\"userInputText must be a string\")\n",
        "    if isinstance(messagesList, list) == False:\n",
        "        raise ValueError(\"messagesList must be a list\")\n",
        "    if isinstance(toolSpecs, list) == False:\n",
        "        raise ValueError(\"toolSpecs must be a list\")\n",
        "\n",
        "    userMessage = {\"role\": \"user\", \"content\": userInputText}\n",
        "    messagesList.append(userMessage)\n",
        "\n",
        "    firstResponse = openAiClient.chat.completions.create(\n",
        "        model=modelName,\n",
        "        messages=messagesList,\n",
        "        tools=toolSpecs,\n",
        "        tool_choice=\"auto\",\n",
        "        temperature=0.4\n",
        "    )\n",
        "\n",
        "    if len(firstResponse.choices) == 0:\n",
        "        fallbackText = \"Apologies, I could not conjure a reply right now.\"\n",
        "        messagesList.append({\"role\": \"assistant\", \"content\": fallbackText})\n",
        "        return fallbackText, messagesList\n",
        "\n",
        "    topChoice = firstResponse.choices[0]\n",
        "    toolCalls = None\n",
        "    if hasattr(topChoice.message, \"tool_calls\"):\n",
        "        toolCalls = topChoice.message.tool_calls\n",
        "\n",
        "    if toolCalls is not None:\n",
        "        if len(toolCalls) > 0:\n",
        "            callIndex = 0\n",
        "            while callIndex < len(toolCalls):\n",
        "                singleToolCall = toolCalls[callIndex]\n",
        "                toolName = singleToolCall.function.name\n",
        "                toolArgsJson = singleToolCall.function.arguments\n",
        "                parsedArgs = {}\n",
        "                if isinstance(toolArgsJson, str) == True:\n",
        "                    parsedArgs = json.loads(toolArgsJson)\n",
        "                toolResult = executeToolCall(toolName, parsedArgs)\n",
        "                toolMessage = {\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": singleToolCall.id,\n",
        "                    \"name\": toolName,\n",
        "                    \"content\": json.dumps(toolResult, ensure_ascii=False)\n",
        "                }\n",
        "                messagesList.append(toolMessage)\n",
        "                callIndex = callIndex + 1\n",
        "\n",
        "            secondResponse = openAiClient.chat.completions.create(\n",
        "                model=modelName,\n",
        "                messages=messagesList,\n",
        "                temperature=0.4\n",
        "            )\n",
        "\n",
        "            if len(secondResponse.choices) > 0:\n",
        "                finalText = secondResponse.choices[0].message.content\n",
        "            else:\n",
        "                finalText = \"Your request was handled, but I could not produce a final message.\"\n",
        "\n",
        "            messagesList.append({\"role\": \"assistant\", \"content\": finalText})\n",
        "            return finalText, messagesList\n",
        "\n",
        "    assistantText = topChoice.message.content\n",
        "    if isinstance(assistantText, str) == False:\n",
        "        assistantText = \"I have a response, but it arrived in an unexpected format.\"\n",
        "    messagesList.append({\"role\": \"assistant\", \"content\": assistantText})\n",
        "    return assistantText, messagesList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8705f492",
      "metadata": {
        "id": "8705f492"
      },
      "outputs": [],
      "source": [
        "def agentRespond(userInputText, messagesList, toolSpecs, modelName=\"gpt-4o-mini\", temperature=0.4):\n",
        "    if isinstance(userInputText, str) == False:\n",
        "        raise ValueError(\"userInputText must be a string\")\n",
        "    if isinstance(messagesList, list) == False:\n",
        "        raise ValueError(\"messagesList must be a list\")\n",
        "    if isinstance(toolSpecs, list) == False:\n",
        "        raise ValueError(\"toolSpecs must be a list\")\n",
        "\n",
        "    userMessage = {\"role\": \"user\", \"content\": userInputText}\n",
        "    messagesList.append(userMessage)\n",
        "\n",
        "    firstResponse = openAiClient.chat.completions.create(\n",
        "        model=modelName,\n",
        "        messages=messagesList,\n",
        "        tools=toolSpecs,\n",
        "        tool_choice=\"auto\",\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    if len(firstResponse.choices) == 0:\n",
        "        fallbackText = \"I could not produce a reply right now.\"\n",
        "        messagesList.append({\"role\": \"assistant\", \"content\": fallbackText})\n",
        "        return fallbackText, messagesList\n",
        "\n",
        "    topChoice = firstResponse.choices[0]\n",
        "\n",
        "    toolCalls = None\n",
        "    if hasattr(topChoice.message, \"tool_calls\"):\n",
        "        toolCalls = topChoice.message.tool_calls\n",
        "\n",
        "    # ----- Tool path -----\n",
        "    if toolCalls is not None:\n",
        "        if len(toolCalls) > 0:\n",
        "            # 1) append the assistant message that contains the tool_calls\n",
        "            assistantToolCallMessage = {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": topChoice.message.content if isinstance(topChoice.message.content, str) else \"\",\n",
        "                \"tool_calls\": []\n",
        "            }\n",
        "\n",
        "            callIndex = 0\n",
        "            while callIndex < len(toolCalls):\n",
        "                singleToolCall = toolCalls[callIndex]\n",
        "                oneToolCallDict = {\n",
        "                    \"id\": singleToolCall.id,\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\n",
        "                        \"name\": singleToolCall.function.name,\n",
        "                        \"arguments\": singleToolCall.function.arguments\n",
        "                    }\n",
        "                }\n",
        "                assistantToolCallMessage[\"tool_calls\"].append(oneToolCallDict)\n",
        "                callIndex = callIndex + 1\n",
        "\n",
        "            messagesList.append(assistantToolCallMessage)\n",
        "\n",
        "            # 2) execute each tool and append its tool result message\n",
        "            callIndex = 0\n",
        "            while callIndex < len(toolCalls):\n",
        "                singleToolCall = toolCalls[callIndex]\n",
        "                toolName = singleToolCall.function.name\n",
        "                toolArgsJson = singleToolCall.function.arguments\n",
        "\n",
        "                parsedArgs = {}\n",
        "                if isinstance(toolArgsJson, str) == True:\n",
        "                    parsedArgs = json.loads(toolArgsJson)\n",
        "\n",
        "                toolResult = executeToolCall(toolName, parsedArgs)\n",
        "\n",
        "                toolMessage = {\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": singleToolCall.id,\n",
        "                    \"name\": toolName,\n",
        "                    \"content\": json.dumps(toolResult, ensure_ascii=False)\n",
        "                }\n",
        "                messagesList.append(toolMessage)\n",
        "\n",
        "                callIndex = callIndex + 1\n",
        "\n",
        "            # 3) finalize\n",
        "            secondResponse = openAiClient.chat.completions.create(\n",
        "                model=modelName,\n",
        "                messages=messagesList,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "            if len(secondResponse.choices) > 0:\n",
        "                finalText = secondResponse.choices[0].message.content\n",
        "            else:\n",
        "                finalText = \"Your request was handled, but a final message was not produced.\"\n",
        "\n",
        "            messagesList.append({\"role\": \"assistant\", \"content\": finalText})\n",
        "            return finalText, messagesList\n",
        "\n",
        "    # ----- No-tool path -----\n",
        "    assistantText = topChoice.message.content\n",
        "    if isinstance(assistantText, str) == False:\n",
        "        assistantText = \"I have a response, but it arrived in an unexpected format.\"\n",
        "    messagesList.append({\"role\": \"assistant\", \"content\": assistantText})\n",
        "    return assistantText, messagesList\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "16549248",
      "metadata": {
        "id": "16549248",
        "outputId": "17ebe80f-2792-4a84-ffbe-71e0271706a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: OPENAI_A***********************************************************************************************************************************************************************SeMA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1786199251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"Hi! I'm Karim, email is karim@example.com. I want a conversion quote. My car's cost is around 7000 dollars all together  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinalReplyLead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magentRespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemoInputLead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolDefinitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Assistant ---\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinalReplyLead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3347743221.py\u001b[0m in \u001b[0;36magentRespond\u001b[0;34m(userInputText, messagesList, toolSpecs, modelName, temperature)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmessagesList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     firstResponse = openAiClient.chat.completions.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessagesList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: OPENAI_A***********************************************************************************************************************************************************************SeMA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "messages = buildInitialMessages(systemPrompt)\n",
        "\n",
        "demoInputLead = (\n",
        "    \"Hi! I'm Karim, email is karim@example.com. I want a conversion quote. My car's cost is around 7000 dollars all together  \"\n",
        ")\n",
        "finalReplyLead, messages = agentRespond(demoInputLead, messages, toolDefinitions)\n",
        "print(\"\\n--- Assistant ---\\n\" + finalReplyLead)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "54a36406",
      "metadata": {
        "id": "54a36406",
        "outputId": "376cc965-615b-465d-b7ff-6c0fa3f351ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U pip\n",
        "%pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5ae6ce0b",
      "metadata": {
        "id": "5ae6ce0b",
        "outputId": "229e1816-c22f-416b-ddc5-c63f014ebd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://796ee03065bcb5f44b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://796ee03065bcb5f44b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def chatWithTools(userText, history):\n",
        "    if isinstance(history, list) == False:\n",
        "        history = []\n",
        "\n",
        "    messagesList = []\n",
        "\n",
        "    systemMessage = {\"role\": \"system\", \"content\": systemPrompt}\n",
        "    messagesList.append(systemMessage)\n",
        "\n",
        "    index = 0\n",
        "    while index < len(history):\n",
        "        historyItem = history[index]\n",
        "        if isinstance(historyItem, dict) == True:\n",
        "            roleValue = historyItem.get(\"role\", None)\n",
        "            contentValue = historyItem.get(\"content\", None)\n",
        "\n",
        "            if isinstance(roleValue, str) == True:\n",
        "                if isinstance(contentValue, str) == True:\n",
        "                    if roleValue == \"user\" or roleValue == \"assistant\":\n",
        "                        messagesList.append({\"role\": roleValue, \"content\": contentValue})\n",
        "        index = index + 1\n",
        "\n",
        "    finalText, _ = agentRespond(userText, messagesList, toolDefinitions)\n",
        "    return finalText\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    fn=chatWithTools,\n",
        "    title=\"FlyMeUP\",\n",
        "    type=\"messages\"\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}